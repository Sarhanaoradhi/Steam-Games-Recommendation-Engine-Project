{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6d9257-2fc1-41e0-bd9d-811d5edba227",
   "metadata": {},
   "source": [
    "After further investigation, it seems I need a different approach to qwen3-Embedding-0.6B. I need to separate \"queries\" with instructions from \"documents\". The structure is assymetrical unlike the regular cosine similarity which compares the same rows and columns to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df995db-17a9-471c-9750-ad087892e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0f8e3d-f112-40ca-aab7-ee69bede2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_df_clean = pd.read_csv(\"sg_df_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe39d72-91f5-4f4d-a39d-72bc69cefe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Queries (Rows)...\n",
      "Encoding Documents (Columns)...\n",
      "Computing Matrix...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load Model \n",
    "model = SentenceTransformer(\n",
    "    \"Qwen/Qwen3-Embedding-0.6B\", \n",
    "    device=\"cuda\", \n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    ")\n",
    "model.max_seq_length = 512 \n",
    "\n",
    "# Setup Data\n",
    "raw_texts = sg_df_clean['about_the_game'].astype(str).tolist()\n",
    "\n",
    "# The specific 'Instruction' for game mechanics\n",
    "instruction = \"Represent this game primarily by its core gameplay mechanics and functional loops, treating the setting and narrative theme as secondary features for similarity matching\\nQuery: \"\n",
    "\n",
    "# Encode \"Rows\" (The Searchers)\n",
    "print(\"Encoding Queries (Rows)...\")\n",
    "query_embeddings = model.encode(\n",
    "    [instruction + t for t in raw_texts], # Prepend instruction to everything\n",
    "    batch_size=64, \n",
    "    normalize_embeddings=True,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "\n",
    "# 4 Encode \"Columns\" (The Targets)\n",
    "print(\"Encoding Documents (Columns)...\")\n",
    "doc_embeddings = model.encode(\n",
    "    raw_texts, # Raw text ONLY\n",
    "    batch_size=64,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "\n",
    "#find similarity\n",
    "print(\"Computing Matrix...\")\n",
    "sim_matrix_tensor = model.similarity(query_embeddings, doc_embeddings)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b41914-9c53-4b83-bca0-c61684ed412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, query_embeddings, doc_embeddings #saving memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a4bf82-7345-4689-9a6c-e7f4fcf99663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to CPU, and convert to NumPy\n",
    "# We use .detach() to ensure the tensor is separated from any computational graph\n",
    "sim_matrix_np = sim_matrix_tensor.to(torch.float32).cpu().detach().numpy()\n",
    "\n",
    "# Convert the resulting NumPy array directly into  DataFrame\n",
    "sim_matrix_df = pd.DataFrame(sim_matrix_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a5c10c-19b9-43b5-b270-c3704d47e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sim_matrix_tensor, sim_matrix_np\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404aac0f-e6e5-4626-aa80-53fab93cdb59",
   "metadata": {},
   "source": [
    "__Cosine Similarity__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe78349-e8cd-49e6-ae2f-ca1ded4666f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e089f9b-8598-474b-9cff-d3f143da7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.read_pickle(\"TF-IDF_V1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1e28c0-a9c5-4d97-af07-1a2dc3f9f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tfidf = cosine_similarity(tfidf_matrix) #cosine similarity for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f25342c-8472-443f-93bc-14a4d15b2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d06f8ff6-57db-4aaf-a5d7-d2a53a1a7905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2936"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "678fcef7-e9bd-433f-8ff6-f05a5702833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sg_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ff70a3a-d92f-4cb0-9805-fb0f349f6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tfidf = sim_matrix_tfidf.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97eed25e-2cc7-40f2-a51d-6baa815c9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w = 0.3\n",
    "embeddings_w = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5c8dea9-9422-4193-bd56-257155eab7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_matrix_1 = tfidf_w * sim_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c697c73e-7331-4e0f-b3e9-6cd3fe2e7726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4110"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sim_matrix_tfidf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0f345cb-87fc-41b3-923a-68f8eb169fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_matrix_2 =embeddings_w * sim_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abea6652-d57e-42f4-a311-0e07b99ca554",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sim_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfe47a16-faec-47d6-8816-e376a1024fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5618"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6b344b9-2152-4e3f-99f0-c5fcc695d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matrix = weighted_matrix_1 + weighted_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24b00c3e-8900-41e2-aec5-811eebe0d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weighted_matrix_1 \n",
    "del weighted_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e194427-365e-4f5d-a055-c3a7a5f38cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(final_matrix, \"Full_cosine_matrix_Qwen-3-6B-V3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23290472-2419-4473-96ea-cd62954e035e",
   "metadata": {},
   "source": [
    "I will skip testing this attempt individually and compare all models in the next document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_5080)",
   "language": "python",
   "name": "bert_5080"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
