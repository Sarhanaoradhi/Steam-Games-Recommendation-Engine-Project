{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49da2c5-1bfa-473e-bf68-80748ac47e63",
   "metadata": {},
   "source": [
    "#### Cosine Similarity (ModernBertEmbed version)\n",
    "\n",
    "This time I am going to use another model to compare to the BERT version of the \"Recommendations engine\". The model will be ModernBERTembed-base. A finetuned model of BERT used for embeddings. It was developed by nomic AI. \n",
    "\n",
    "Some features of ModernBertEmbed:\n",
    "\n",
    "* Flash attention: It is meant to be more efficient as it used Flash Attention, an algorithm to process text faster on the GPU  \n",
    "* Longer Context: up to  8192 tokens vs 512 in BERT\n",
    "* Prefixes: It requires a prefix of either \"search_document:\" which signifies that you are looking for answers and \"search_query:\" which is for questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39572f71-5d1c-4c8d-9598-f2aaa6d8a60f",
   "metadata": {},
   "source": [
    "Let's install dependencies first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded61b6a-f6ec-491f-998c-52f559b600af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.48.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: torch in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (2.10.0.dev20251210+cu128)\n",
      "Requirement already satisfied: filelock in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (2.4.0rc1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from transformers>=4.48.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.48.0) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.48.0) (4.15.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from tqdm>=4.27->transformers>=4.48.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from requests->transformers>=4.48.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from requests->transformers>=4.48.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from requests->transformers>=4.48.0) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from requests->transformers>=4.48.0) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"transformers>=4.48.0\" sentence-transformers accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6f48b5-e7e0-47bb-beb1-c4b9d935ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Using cached flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from flash-attn) (2.10.0.dev20251210+cu128)\n",
      "Collecting einops (from flash-attn)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch->flash-attn) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch->flash-attn) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch->flash-attn) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch->flash-attn) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch->flash-attn) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from torch->flash-attn) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (pyproject.toml): started\n",
      "  Building wheel for flash-attn (pyproject.toml): finished with status 'error'\n",
      "Failed to build flash-attn\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for flash-attn (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [157 lines of output]\n",
      "  C:\\Users\\icefo\\miniconda3\\envs\\bert_5080\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \n",
      "          License :: OSI Approved :: BSD License\n",
      "  \n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  \n",
      "  \n",
      "  torch.__version__  = 2.10.0.dev20251210+cu128\n",
      "  \n",
      "  \n",
      "  running bdist_wheel\n",
      "  W1223 22:15:36.737000 34796 site-packages\\torch\\utils\\cpp_extension.py:659] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  Guessing wheel URL:  https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.10cxx11abiTRUE-cp311-cp311-win_amd64.whl\n",
      "  Precompiled wheel not found. Building from source...\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\bert_padding.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\flash_attn_interface.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\flash_attn_triton.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\flash_attn_triton_og.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\flash_blocksparse_attention.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\flash_blocksparse_attn_interface.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  copying flash_attn\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\n",
      "  creating build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\benchmark_attn.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\benchmark_flash_attention_fp8.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\benchmark_mla_decode.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\benchmark_split_kv.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\flash_attn_interface.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\generate_kernels.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\padding.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\setup.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\test_attn_kvcache.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\test_flash_attn.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\test_kvcache.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\test_util.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  copying hopper\\__init__.py -> build\\lib.win-amd64-cpython-311\\hopper\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\ampere_helpers.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\blackwell_helpers.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\block_info.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\fast_math.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\flash_bwd.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\flash_bwd_postprocess.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\flash_bwd_preprocess.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\flash_fwd.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\flash_fwd_sm100.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\hopper_helpers.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\interface.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\mask.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\mma_sm100_desc.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\named_barrier.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\pack_gqa.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\pipeline.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\seqlen_info.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\softmax.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\tile_scheduler.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\utils.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  copying flash_attn\\cute\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\cute\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\bench.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\bwd_prefill.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\bwd_prefill_fused.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\bwd_prefill_onekernel.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\bwd_prefill_split.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\bwd_ref.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\fp8.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\fwd_decode.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\fwd_prefill.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\fwd_ref.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\interface_fa.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\test.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\train.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\utils.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  copying flash_attn\\flash_attn_triton_amd\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\flash_attn_triton_amd\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\layers\n",
      "  copying flash_attn\\layers\\patch_embed.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\layers\n",
      "  copying flash_attn\\layers\\rotary.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\layers\n",
      "  copying flash_attn\\layers\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\layers\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\losses\n",
      "  copying flash_attn\\losses\\cross_entropy.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\losses\n",
      "  copying flash_attn\\losses\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\losses\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\baichuan.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\bert.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\bigcode.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\btlm.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\falcon.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\gpt.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\gptj.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\gpt_neox.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\llama.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\opt.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\vit.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  copying flash_attn\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\models\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\modules\n",
      "  copying flash_attn\\modules\\block.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\modules\n",
      "  copying flash_attn\\modules\\embedding.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\modules\n",
      "  copying flash_attn\\modules\\mha.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\modules\n",
      "  copying flash_attn\\modules\\mlp.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\modules\n",
      "  copying flash_attn\\modules\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\modules\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\ops\n",
      "  copying flash_attn\\ops\\activations.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\n",
      "  copying flash_attn\\ops\\fused_dense.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\n",
      "  copying flash_attn\\ops\\layer_norm.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\n",
      "  copying flash_attn\\ops\\rms_norm.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\n",
      "  copying flash_attn\\ops\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\benchmark.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\distributed.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\generation.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\library.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\pretrained.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\testing.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\torch.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  copying flash_attn\\utils\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\utils\n",
      "  creating build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\cross_entropy.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\k_activations.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\layer_norm.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\linear.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\mlp.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\rotary.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  copying flash_attn\\ops\\triton\\__init__.py -> build\\lib.win-amd64-cpython-311\\flash_attn\\ops\\triton\n",
      "  running build_ext\n",
      "  W1223 22:15:37.272000 34796 site-packages\\torch\\utils\\cpp_extension.py:484] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'flash_attn_2_cuda' extension\n",
      "  creating build\\temp.win-amd64-cpython-311\\Release\\csrc\\flash_attn\n",
      "  creating build\\temp.win-amd64-cpython-311\\Release\\csrc\\flash_attn\\src\n",
      "  \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\flash_attn -IC:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\flash_attn\\src -IC:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include -IC:\\Users\\icefo\\miniconda3\\envs\\bert_5080\\Lib\\site-packages\\torch\\include -IC:\\Users\\icefo\\miniconda3\\envs\\bert_5080\\Lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\include\" -IC:\\Users\\icefo\\miniconda3\\envs\\bert_5080\\include -IC:\\Users\\icefo\\miniconda3\\envs\\bert_5080\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt\" /EHsc /Tpcsrc/flash_attn/flash_api.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\csrc\\flash_attn\\flash_api.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=flash_attn_2_cuda /std:c++17\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-O3'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-std=c++17'\n",
      "  flash_api.cpp\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2039: 'is_unsigned_v': is not a member of 'cutlass::platform'\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/integer_subbyte.h(235): note: see declaration of 'cutlass::platform'\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(860): note: see reference to class template instantiation 'cutlass::detail::FpBitRepresentation<uint32_t,32,8,23,cutlass::detail::NanInfEncoding::IEEE_754,true>' being compiled\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(950): note: see reference to function template instantiation 'auto cutlass::detail::fp_encoding_selector<cutlass::detail::FpEncoding::E8M23>(void)' being compiled\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(1211): note: see reference to class template instantiation 'cutlass::float_exmy_base<T,Derived>' being compiled\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2065: 'is_unsigned_v': undeclared identifier\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2275: 'cutlass::detail::FpBitRepresentation<uint32_t,32,8,23,cutlass::detail::NanInfEncoding::IEEE_754,true>::Storage': illegal use of this type as an expression\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2059: syntax error: ','\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2238: unexpected token(s) preceding ';'\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2275: 'cutlass::detail::FpBitRepresentation<uint8_t,8,4,3,cutlass::detail::NanInfEncoding::CANONICAL_ONLY,false>::Storage': illegal use of this type as an expression\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2275: 'cutlass::detail::FpBitRepresentation<uint8_t,8,8,0,cutlass::detail::NanInfEncoding::CANONICAL_ONLY,false>::Storage': illegal use of this type as an expression\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2275: 'cutlass::detail::FpBitRepresentation<uint8_t,4,2,1,cutlass::detail::NanInfEncoding::NONE,true>::Storage': illegal use of this type as an expression\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2275: 'cutlass::detail::FpBitRepresentation<uint8_t,6,2,3,cutlass::detail::NanInfEncoding::NONE,true>::Storage': illegal use of this type as an expression\n",
      "  C:\\Users\\icefo\\AppData\\Local\\Temp\\pip-install-clbzcg81\\flash-attn_538066262bf94e4b8c912e3eae78869c\\csrc\\cutlass\\include\\cutlass/exmy_base.h(404): error C2275: 'cutlass::detail::FpBitRepresentation<uint8_t,6,3,2,cutlass::detail::NanInfEncoding::NONE,true>::Storage': illegal use of this type as an expression\n",
      "  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for flash-attn\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "Failed to build installable wheels for some pyproject.toml based projects\n",
      "\n",
      "flash-attn\n"
     ]
    }
   ],
   "source": [
    "pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904f228-ba55-4de0-9bdf-51e32db437ee",
   "metadata": {},
   "source": [
    "Flash attention failed to install so I will not use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d243814b-9a8d-459b-86e9-52398a1f0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hf_xet in c:\\users\\icefo\\miniconda3\\envs\\bert_5080\\lib\\site-packages (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bbe4190-5a6e-4cfe-bdd2-5563f63f6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965df2ad-5fbd-456a-84b9-ec62c38d6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_df_clean = pd.read_csv(\"sg_df_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99f3ede-55f6-449b-b73d-59197f3bc298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'name', 'release_date', 'detailed_description', 'about_the_game',\n",
       "       'short_description', 'metacritic_score', 'categories', 'genres',\n",
       "       'positive', 'negative', 'estimated_owners', 'tags', 'user_reviews',\n",
       "       'tags_dict', 'top_5_tags', 'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404385ce-cb39-44f0-80a7-18b12ead45ed",
   "metadata": {},
   "source": [
    "Let's load and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ec6c62-ab48-45cb-93a1-3627c1955c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting text...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731046f21c024678932c4f6b5fb542e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load Model\n",
    "model = SentenceTransformer('nomic-ai/modernbert-embed-base', device='cuda')\n",
    "model.max_seq_length = 512 #to save on memory\n",
    "\n",
    "# Format Text\n",
    "print(\"Formatting text...\")\n",
    "texts = []  # Create an empty list\n",
    "\n",
    "# Loop through every row in the column\n",
    "for text in sg_df_clean['about_the_game']:\n",
    "    \n",
    "    #  Add the prefix\n",
    "    new_text = \"search_document: \" + str(text)  #We use search_document to tell the model we are looking for answers, not questions. It is related to how this model was trained.\n",
    "    \n",
    "    #  Add to the list\n",
    "    texts.append(new_text)\n",
    "\n",
    "# Generate Embeddings \n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=256,  \n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "sg_df_clean[\"embeddings\"] = list(embeddings)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4be8111-6f33-4831-9f2a-948aaab4083f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.011169485, -0.013404448, 0.04623577, -0.04...\n",
       "1        [-0.012440475, 0.007200008, -0.03891932, 0.017...\n",
       "2        [-0.0075391605, -0.03697401, 0.0120488545, -0....\n",
       "3        [-0.043684047, 0.040152546, 0.02400123, -0.021...\n",
       "4        [-0.021892304, 0.031989895, -0.03811961, -0.02...\n",
       "                               ...                        \n",
       "72366    [0.042880114, 0.024679743, 0.037190583, -0.099...\n",
       "72367    [0.009328879, -0.03561734, 0.04149969, -0.0447...\n",
       "72368    [-0.0095696505, -0.037554722, 0.005656592, -0....\n",
       "72369    [-0.0069766436, 0.06417681, 0.013568733, -0.07...\n",
       "72370    [0.012446061, 0.047930624, 0.015035044, -0.049...\n",
       "Name: embeddings, Length: 72371, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_df_clean[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5108da85-c4c8-4ef3-9a8f-9a686811ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61c0cf5f-f281-4f28-8d37-560e8822026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.array(sg_df_clean[\"embeddings\"].to_list()) #we need to \"unpack\" the column to create a matrix to use for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cd2b11b-8e1e-4946-a617-b48e3b0bad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25e57843-15e8-481c-bf11-1326a4d5658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_embeddings = cosine_similarity(embedding_matrix) #cosine similarity for the new embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21445dc0-b7b4-49ab-9ed5-0686c409f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.read_pickle(\"TF-IDF_V1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e8454a6-e1e5-4d8a-bd96-5ff7b7b6befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tfidf = cosine_similarity(tfidf_matrix) #cosine similarity for tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde8d8f-755c-41c8-8474-a863c2063f4f",
   "metadata": {},
   "source": [
    "Let's free up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d489cc0-44b2-42ba-b14b-27b5d5b7768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b3dbf1c-83a4-404f-8089-13a406a148ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf_matrix\n",
    "del sg_df_clean\n",
    "del embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33c8fdc0-5c01-40af-8175-8713f1baae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tfidf = sim_matrix_tfidf.astype(np.float32) #saving memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82356c88-0a6a-40fd-8114-63ab15b89ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05ff8e97-62b3-48fa-b309-8ad25d90604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_embeddings = sim_matrix_embeddings.astype(np.float32) #saving memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49aaaa4f-d3e5-4fc4-a6a3-72a7d1b614f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f6a933-2861-4280-a1fb-58816b74130d",
   "metadata": {},
   "source": [
    "##### Cosine Similarity\n",
    "\n",
    "We will now repeat the same steps as notebook 2 to create the cosine similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b1f2d-f4a3-4aae-965a-0cfdac96ce9f",
   "metadata": {},
   "source": [
    "Let's add the weights to each matrix, I am going to decrease tf-idf weight to 0.3 as it has less context than the \"about the game\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb88aec1-90ad-42b7-9281-77c53b04b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w = 0.3\n",
    "embeddings_w = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9750ffe-0ff5-4c99-a88b-89ef6e73b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_matrix_1 = tfidf_w * sim_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a17804a-a1c1-40f1-9db2-740d981fb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sim_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e115de60-e8f6-4c30-bdf1-edaef968cdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a156573e-247b-4433-b07e-fdc5f45d5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_matrix_2 =embeddings_w * sim_matrix_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "693a4ced-f6c8-4692-b637-5c96d641028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sim_matrix_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a847908b-8bc2-4911-b001-9cddee6f981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16cb2620-f144-43fa-b13b-3d73b9aaf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matrix = weighted_matrix_1 + weighted_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83a9b940-735f-44c8-8715-aaa1f9da1dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d993ce3-027d-4c1b-b27a-933e8f538ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weighted_matrix_1 \n",
    "del weighted_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47130330-707f-4d77-a965-9dbe9e6c0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(final_matrix, \"Full_cosine_matrix_modernbertembed.pkl\") #exporting the matrix to pickle file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_5080)",
   "language": "python",
   "name": "bert_5080"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
