{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9857c65-f1e1-41da-863b-d1d0779b37e6",
   "metadata": {},
   "source": [
    "#### Cosine Similarity (EmbeddingGemma-300m version)\n",
    "\n",
    "This time I am going to use another model to compare to the other versions of the \"Recommendations engine\". The model will be EmbeddingGemma 300m. A lightweight developed by google for embeddings. This model is small in size and is meant to run on less powerful hardware. It is built from the same technology used for Gemini LLM and was trained on more than 100 languages. It has less context window (2048 vs 8192 tokens), but it will not matter much for this project as we cannot use the entirety of it due to hardware limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e9d807-a4b7-425f-8764-bbda05bb25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fbd59b-01e4-4bef-99e1-677bc2feb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_df_clean = pd.read_csv(\"sg_df_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0fd9a7b-c7d9-491d-bd3c-088ad1cc6bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'name', 'release_date', 'detailed_description', 'about_the_game',\n",
       "       'short_description', 'metacritic_score', 'categories', 'genres',\n",
       "       'positive', 'negative', 'estimated_owners', 'tags', 'user_reviews',\n",
       "       'tags_dict', 'top_5_tags', 'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af7087f-747b-46e5-8270-80254579f092",
   "metadata": {},
   "source": [
    "I cannot access the model directly. I need to login and agree to terms and services first and use my token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b64925db-2537-410b-947e-ffb1d324918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0858986cedda4dc5baab1cce129c1598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/573 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\icefo\\miniconda3\\envs\\bert_5080\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\icefo\\.cache\\huggingface\\hub\\models--google--embeddinggemma-300m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe6f529d0984325a981d7b606ad4197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4c7ed73f854c4d95cf04a1a58afd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0decc398df547069b5b8ae611d7b003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7caf511f7748f48dd484e6e3d00759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad282e1e244270a0c2ea09ea312b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ecce8058a4e97b545cc88ba5ac0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2890c9fd044df7836de2ec0d875e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd97e59b4ba44468eec05b91f4d56cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6372b0046e453c9073b3fa6d2b9ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8a14c6d4e1430e951ab817e49926fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aab9f157fe64763b8c14a6e5c632aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b150c8061b574d50bc5b61fefd324a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fa2334c29e462788752783b6453327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9f62dfcf7546ca83f097da6b6fe02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0852ab76a235411398ee7f3c7f92cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\") #my token\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('google/embeddinggemma-300m', device='cuda') #model loading\n",
    "model.max_seq_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256ad9d-df4c-480e-b7c1-0fbe9b4937e6",
   "metadata": {},
   "source": [
    "Let us use the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2dc997-fe1e-493b-8af0-2e0a004065c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gemma (FP32)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3e220310574921ae47c79d60e0e784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = []\n",
    "for text in sg_df_clean['about_the_game']:\n",
    "    \n",
    "    texts.append(f\"title: none | text: {str(text)}\") # The 'title: none' instruction is needed for accuracy. It tells the model to just read the text without a title in mind.\n",
    "\n",
    "# Generate Embeddings\n",
    "print(\"Running Gemma (FP32)...\")\n",
    "embeddings = model.encode(\n",
    "    texts, \n",
    "    batch_size=256, \n",
    "    show_progress_bar=True, \n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "sg_df_clean['embeddings_gemma'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4deee71-e788-44fb-880a-e5ca0728ae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.01832982, 0.014348313, -0.006759636, 0.025...\n",
       "1        [-0.052234292, -0.021033615, 0.056520652, 0.02...\n",
       "2        [-0.067020446, 0.0425993, -0.04444981, 0.03402...\n",
       "3        [-0.037949294, -0.014005198, 0.024563793, 0.00...\n",
       "4        [-0.018616172, 0.07883144, -0.011520526, -0.03...\n",
       "                               ...                        \n",
       "72366    [-0.04330082, 0.026356028, -0.030316208, 0.017...\n",
       "72367    [-0.010327066, -0.005349967, 0.005656356, 0.01...\n",
       "72368    [-0.05570912, -0.0006502688, 0.04861189, 0.044...\n",
       "72369    [-0.034575716, -0.022674508, 0.020543693, 0.00...\n",
       "72370    [-0.06345311, -0.019693647, -0.020096852, 0.03...\n",
       "Name: embeddings_gemma, Length: 72371, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_df_clean['embeddings_gemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72810898-2dfc-4f43-92d5-cb3225dc8a98",
   "metadata": {},
   "source": [
    "##### Cosine Similarity\n",
    "\n",
    "We will repeat the same steps from notebooks 2 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db3ea8ca-22eb-4083-87f2-5bd749fe9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f2c0fb-40be-4df8-babf-b289c7d89447",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.array(sg_df_clean[\"embeddings_gemma\"].to_list()) #we need to \"unpack\" the column to create a matrix to use for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60861a44-ecf8-4996-a4a9-419f0696f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c1c9294-c71a-481e-b4e6-ef98cc6597e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_embeddings = cosine_similarity(embedding_matrix) #cosine similarity for the new embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "948163f3-4edc-4967-adc0-fb8c59e2296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.read_pickle(\"TF-IDF_V1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb097f-3fcb-4404-a90e-418537da4505",
   "metadata": {},
   "source": [
    "I need to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5ec16e2-a304-4049-94c4-2172d65a3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_fp32 = tfidf_matrix.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ef436e7-a9cc-4947-b9f2-7e9ea5646bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211122ec-edd3-4eee-bad6-b9f5b49abd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5ada8-b97d-4237-91e8-de5eba1b3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e72ac67a-670b-47e6-b44d-2098de0c85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tfidf = cosine_similarity(tfidf_matrix_fp32) #cosine similarity for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "631b122a-f69e-4be5-8adf-5acdb5b43cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64fe1f33-9bed-4758-99bf-9823b21650df",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sg_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5aa9e15b-ac0d-440d-bbad-4c43e7a355e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1124d3f6-bcd7-456c-a486-99c41436046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tfidf = sim_matrix_tfidf.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31cbc6eb-299f-4580-81ed-f9368e800857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17e2d37a-578a-4f81-91c6-059bc11f45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_embeddings = sim_matrix_embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c01fafdc-5819-4820-bd6d-5ddbebc6102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae7cc6e7-dcf1-418b-891a-45bbc2b96547",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w = 0.3\n",
    "embeddings_w = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "041dd5da-04f8-443c-8396-45ff365b8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_matrix_1 = tfidf_w * sim_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72638801-d2fc-4538-8f9e-3515ba8abd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sim_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1226233-fbe2-48f4-a845-1c457f718d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95478617-251f-4819-a422-66f523bb064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_matrix_2 =embeddings_w * sim_matrix_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6651d82-586b-484b-91e8-d15368253e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sim_matrix_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28ef11f1-19e6-4c18-84b1-c7d1d96ba6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6027190-768f-46d6-9e9b-0c1dccaaebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matrix = weighted_matrix_1 + weighted_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5c7c4bb-d3df-421e-a97d-97325ffa2f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "baf3e44c-f83d-4fff-bff7-1410b853210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weighted_matrix_1 \n",
    "del weighted_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cad774c-2303-4b27-b99d-3d4f09d4d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(final_matrix, \"Full_cosine_matrix_EmbeddingGemma.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_5080)",
   "language": "python",
   "name": "bert_5080"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
